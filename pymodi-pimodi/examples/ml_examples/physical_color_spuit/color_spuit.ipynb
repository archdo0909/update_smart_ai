{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install --upgrade opencv-python numpy pymodi tensorflow --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PyMODI (v0.9.1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from IPython.display import display, Image, clear_output\n",
    "import time\n",
    "import modi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a necessary helper method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASwAAAEsCAIAAAD2HxkiAAAE8ElEQVR4Ae3BMQEAAAzCsCEAafh3gYbJ4GmiOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAO6pzAHZU5wDsqM4B2FGdA7CjOgdgR3UOwI7qHIAd1TkAOw+5ooGcH5oqdgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([238,  13,  77])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def new_color():\n",
    "    rgb = np.random.randint(0, 255, size=3)\n",
    "    \n",
    "    solid_color = np.zeros((300, 300, 3), np.uint8)\n",
    "    solid_color[:] = rgb[::-1]\n",
    "    _, ret = cv2.imencode('.png', solid_color)\n",
    "    image = Image(data=ret)\n",
    "    display(image)\n",
    "    return rgb\n",
    "\n",
    "new_color()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intialize MODI object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Ser Task.\n",
      "Start initializing connected MODI modules\n",
      "Env (392) has been connected!\n",
      "Led (3712) has been connected!\n"
     ]
    }
   ],
   "source": [
    "bundle = modi.MODI()\n",
    "\n",
    "env = bundle.envs[0]\n",
    "led = bundle.leds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASwAAAEsCAIAAAD2HxkiAAAE7klEQVR4Ae3BMQEAAAzCsCEZZ9jjmwyeJkp9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Cj1AdgR6kPwI5SH4AdpT4AO0p9AHaU+gDsKPUB2FHqA7Dzdal3wzq/UoEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22.69, 25.41, 18.46] -> [0.69019608 0.97647059 0.44313725]\n",
      "[22.77, 25.43, 18.47] -> [0.69019608 0.97647059 0.44313725]\n",
      "[22.94, 25.66, 18.58] -> [0.69019608 0.97647059 0.44313725]\n",
      "[22.94, 25.89, 18.72] -> [0.69019608 0.97647059 0.44313725]\n",
      "[23.59, 25.89, 18.72] -> [0.69019608 0.97647059 0.44313725]\n",
      "[24.82, 26.85, 19.45] -> [0.69019608 0.97647059 0.44313725]\n",
      "[24.82, 28.27, 20.51] -> [0.69019608 0.97647059 0.44313725]\n",
      "[25.12, 28.62, 20.77] -> [0.69019608 0.97647059 0.44313725]\n",
      "[25.13, 28.62, 20.77] -> [0.69019608 0.97647059 0.44313725]\n",
      "[25.13, 28.65, 20.77] -> [0.69019608 0.97647059 0.44313725]\n"
     ]
    }
   ],
   "source": [
    "train_set = []\n",
    "label_set = []\n",
    "\n",
    "clear_output(wait=True)\n",
    "new_color()\n",
    "input(\"Place your env module on the color and press Enter when ready...\")\n",
    "\n",
    "for i in range(30):\n",
    "    clear_output(wait=True)\n",
    "    rgb = new_color()\n",
    "    led.rgb = rgb // 5\n",
    "    time.sleep(0.5)\n",
    "    for i in range(10):\n",
    "        label = rgb / 255\n",
    "        data = [env.red, env.green, env.blue]\n",
    "        label_set.append(label)\n",
    "        train_set.append(data)\n",
    "        print(f\"{data} -> {label}\")\n",
    "        time.sleep(0.1)\n",
    "    time.sleep(0.1)\n",
    "\n",
    "train_set = np.array(train_set)\n",
    "label_set = np.array(label_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the generated dataset and save them to ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 3)\n",
      "(300, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_set.shape)\n",
    "print(label_set.shape)\n",
    "\n",
    "np.save('./data/label_set.npy', label_set, allow_pickle=True)\n",
    "np.save('./data/train_set.npy', train_set, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, save_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "train_set = np.load('./data/train_set.npy', allow_pickle=True)\n",
    "label_set = np.load('./data/label_set.npy', allow_pickle=True)\n",
    "\n",
    "shuffled_idx = np.random.permutation(train_set.shape[0])\n",
    "split_idx = int(train_set.shape[0] * 0.8)\n",
    "X_Train = train_set[shuffled_idx[:split_idx]]\n",
    "y_Train = label_set[shuffled_idx[:split_idx]]\n",
    "X_Test = train_set[shuffled_idx[split_idx:]]\n",
    "y_Test = label_set[shuffled_idx[split_idx:]]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_shape=(3,)))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "EPOCH = 50\n",
    "BATCH = 8\n",
    "model.fit(X_Train, y_Train, epochs=EPOCH, batch_size=BATCH, verbose=1,\n",
    "          validation_data=(X_Test, y_Test))\n",
    "\n",
    "save_model(model, 'weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import time\n",
    "\n",
    "model = load_model('weights.h5')\n",
    "\n",
    "while True:\n",
    "    clear_ouput(wait=True)\n",
    "    rgb_read = np.array([env.red, env.green, env.blue])[np.newaxis, :]\n",
    "    result = model.predict(rgb_read)[0] * 255 // 1\n",
    "    color = np.zeros((300, 300, 3), np.uint8)\n",
    "    color[:] = result[::-1]\n",
    "    _, ret = cv2.imencode('.png', color)\n",
    "    image = Image(data=ret)\n",
    "    display(image)\n",
    "    if cv2.waitKey(50) & 0xFF == ord('q'):\n",
    "        break\n",
    "    led.rgb = result // 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
